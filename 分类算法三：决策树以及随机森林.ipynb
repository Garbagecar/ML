{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19e57645-21bf-4c12-a440-5483178f675c",
   "metadata": {},
   "source": [
    "# 分类算法三：决策树以及随机森林"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad9b57-25fd-4873-ae32-dc32e4f4f15f",
   "metadata": {},
   "source": [
    "## <mark style=background-color:pink>一、决策树<mark>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b326f49f-be86-4b3b-824f-07f9140456e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.认识决策树\n",
    "\n",
    "- 决策树思想的来源非常朴素，程序设计中的条件分支结构就是if-then结构，最早的决策树就是利用这类结构分割数据的一种分类学习方法\n",
    "\n",
    "例：比如母亲给女儿介绍男朋友取相亲，女儿要母亲先简单描述一下这个人看看是不是自己感兴趣的类型，其实相当于将这个相亲对象分为感兴趣的类型和不感兴趣的类型\n",
    "\n",
    "|第一层判断：年龄<30|第二层判断：样貌出众|第三层判断：收入高中低|第四层判断：是公务员|最终：类型|\n",
    "|-------|-------|-----|-------|----|\n",
    "|  否    |   -  |  -  |   -   |不感兴趣|    \n",
    "|  是    |   否  |  -  |   -   |不感兴趣|\n",
    "|  是    |   是  |  低  |   -   |不感兴趣|\n",
    "|  是    |   是  |  中  |   否   |不感兴趣|\n",
    "|  是    |   是  |  中  |   是   |感兴趣|\n",
    "|  是    |   是  |  高  |   -   |感兴趣|\n",
    "\n",
    "\n",
    "- 上述可以画成**树状图**\n",
    "- 有判断的顺序，也就是从第一层到第四层，可以看出女儿心中对各个方面看中的顺序是：年龄>样貌>收入>公务员"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e70430-dac8-46e8-8e56-55672ba3903a",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### 2.信息论基础\n",
    "\n",
    "例：银行贷款数据如下，如何去判断是否能得到贷款？\n",
    "\n",
    "|ID|年龄|有工作|有自己的房子|信贷情况|类别|\n",
    "|--|----|-----|-----------|-------|----|\n",
    "|1|青年|0|0|一般|否|\n",
    "|2|青年|0|0|好|否|\n",
    "|3|青年|1|0|好|是|\n",
    "|4|青年|1|1|一般|是|\n",
    "|5|青年|0|0|一般|否|\n",
    "|6|中年|0|0|一般|否|\n",
    "|7|中年|0|0|好|否|\n",
    "|8|中年|1|1|好|是|\n",
    "|9|中年|0|1|非常好|是|\n",
    "|10|中年|0|1|非常好|是|\n",
    "|11|老年|0|1|非常好|是|\n",
    "|12|老年|0|1|好|是|\n",
    "|13|老年|1|1|好|是|\n",
    "|14|老年|1|0|非常好|是|\n",
    "|15|老年|0|0|一般|否|\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "例：假如有32支要进行比赛的球队，**如果不知道任何一个队伍的信息**，要猜哪一支球队获胜，该怎么猜？\n",
    "- ①1-16：将32支球队一分为2，猜获胜队伍在编号1-16的队伍中\n",
    "- ②9-16：又将1-16这16支队伍一分为2，猜获胜队伍在编号9-16的队伍中\n",
    "- ③13-16\n",
    "- ④13、14\n",
    "- ⑤13\n",
    "- 在二分法下，最多需要5次(因为2的五次方为32)，就可以选择出一支队伍(13)作为猜测的队伍\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d64d71-0f48-4a69-99d4-c7cedd2edfbd",
   "metadata": {},
   "source": [
    "#### 信息的度量和作用\n",
    "\n",
    "- 信息的度量单位：比特bit\n",
    "- 如在球队例题中，log_2(32)=5 bit\n",
    "- 香农发现：5 = - (1/32*log_2(1/32)+1/32*log_2(1/32)+...+1/32*log_2(1/32))\n",
    "- 香农指出：' 获胜队伍 '的信息**代价**应该比5bit少，比如对这些球队不再是一无所知(**此时相当于没有信息**)\n",
    "- **在告知一些球队的信息后**\n",
    "- 它的准确信息量(**代价**)应该是**H=-(P1\\*log_2(P1)+P2\\*log_2(P2)+P3\\*log_2(P3)+....+P32\\*log_2(P32))**\n",
    "- 比如开放信息：德国队获胜的概率为1/6，巴西队获胜的概率为1/6，中国队获胜的概率1/10...\n",
    "- H = - (1/6*log_2(1/6)+1/6*log_2(1/6)+1/10*log_2(1/10)...) < 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b52c5e-ff04-4f87-bf74-bb77a9029526",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 信息熵\n",
    "- H的专业术语称之为**信息熵**，单位为比特bit\n",
    "- 公式：$H(X)=-\\sum_{x∈X}P(x)log_2 P(x)$\n",
    "- 如在球队例题中，当对球队一无所知时，相当于他们获胜的概率相同，对应的**信息熵**就应该为5bit\n",
    "- 当你对这些球队有一定了解时的**信息熵**就应当比5bit小\n",
    "- **信息和消除不确定性是相互联系的：信息熵越大，不确定性越大**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b051737c-c4d9-4ebc-a4f1-da3473a43cfa",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 决策树的划分依据之一：信息增益\n",
    "- 训练数据集D的信息熵：H(D)\n",
    "- 特征$A_i$给定条件下数据集D的信息条件熵：H(D|$A_i$)\n",
    "- 特征$A_i$对训练数据集D的**信息增益：g(D,$A_i$) = H(D) - H(D|$A_i$)**\n",
    "- 注：**信息增益表示得知特征X的信息而使得类Y的信息的不确定性减少的程度**，也就是得知一个特征条件后，减少的信息熵的大小"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d6db50-e590-4415-bcca-ee8b67c885bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 信息熵H(D)以及条件熵H(D|$A_i$)的计算\n",
    "\n",
    "信息熵H(D)的计算：\n",
    "- $H(D)=-\\sum_{K=1}^{K} \\frac{|C_{k}|}{|D|}log \\frac{|C_{k}|}{|D|}$\n",
    "- $|C_{k}|$表示属于某个类别的样本数\n",
    "\n",
    "条件熵H(D)的计算：\n",
    "- $H(D|A_i)=\\sum_{i=1}^{n} \\frac{|D_{i}|}{|D|} H(D_{i})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae09aace-cc84-4d5b-8aa8-609b13a0dad3",
   "metadata": {},
   "source": [
    "#### 以银行贷款的数据为例计算信息熵和信息增益\n",
    "\n",
    "|ID|年龄|有工作|有自己的房子|信贷情况|类别|\n",
    "|--|----|-----|-----------|-------|----|\n",
    "|1|青年|0|0|一般|否|\n",
    "|2|青年|0|0|好|否|\n",
    "|3|青年|1|0|好|是|\n",
    "|4|青年|1|1|一般|是|\n",
    "|5|青年|0|0|一般|否|\n",
    "|6|中年|0|0|一般|否|\n",
    "|7|中年|0|0|好|否|\n",
    "|8|中年|1|1|好|是|\n",
    "|9|中年|0|1|非常好|是|\n",
    "|10|中年|0|1|非常好|是|\n",
    "|11|老年|0|1|非常好|是|\n",
    "|12|老年|0|1|好|是|\n",
    "|13|老年|1|1|好|是|\n",
    "|14|老年|1|0|非常好|是|\n",
    "|15|老年|0|0|一般|否|\n",
    "\n",
    "D中有9个'是'(发放贷款)，6个'否'(不发放贷款)\n",
    "- **H(D) = -(9/15*log_2(9/15)+6/15*log_2(6/15)) = 0.971**\n",
    "\n",
    "特征'年龄'的信息增益：**g(D,'年龄') = H(D) - H(D|'年龄')**\n",
    "- '年龄'：有三个类别：青年、中年、老年\n",
    "- **H(D|'年龄') = -(5/15*H('青年')+5/15*H('中年')+5/15*H('老年'))**\n",
    "\n",
    "五个'青年'中有2个'是'(发放贷款)，3个'否'(不发放贷款)\n",
    "- **H('青年') = -(2/5*log_2(2/5)+3/5*log_2(3/5))**\n",
    "\n",
    "五个'中年'中有有2个'是'(发放贷款)，3个'否'(不发放贷款)\n",
    "- **H('中年') = -(2/5*log_2(2/5)+3/5*log_2(3/5))**\n",
    "\n",
    "五个'老年'中有有4个'是'(发放贷款)，1个'否'(不发放贷款)\n",
    "- **H('老年') = -(4/5*log_2(4/5)+1/5*log_2(1/5))**\n",
    "\n",
    "最后就可以计算出特征'年龄'的信息增益\n",
    "- 同样也可以计算出其他特征'工作'、'房子'、'信贷'等特征的信息增益\n",
    "- 比较四个特征之间的信息增益大小，**信息增益最大的，最有特征**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219075ce-3f30-4ad2-b86a-f924c9b9fc7b",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### 3.决策树的生成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c109ce83-38c4-4f83-ad9a-347191fac1be",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 常用决策树使用的算法\n",
    "ID3\n",
    "- 信息增益 最大的准则\n",
    "\n",
    "C4.5\n",
    "- 信息增益比 最大的准则\n",
    "\n",
    "CART\n",
    "- 回归树：平方误差 最小\n",
    "- 分类树：**基尼系数** 最小的准则 在sklearn中可以选择划分的默认原则\n",
    "- 基尼系数：划分更加仔细"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e0b292-450b-494c-be69-0711d30a3b73",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### sklearn中的决策树\n",
    "\n",
    "- 类：**sklearn.tree.DecisionTreeClassifier**\n",
    "- 实例化方法：**sklearn.tree.DecisionTreeClassifier(criterion='gini',max_depth=,random_state=)**\n",
    "- criterion：默认是'gini'系数，也可以选择信息增益的熵'entropy'\n",
    "- max_depth：树的深度大小\n",
    "- random_state：随机种子\n",
    "- decision_path：返回决策树的路径"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed387953-8f16-426c-9604-a83a398148f9",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### 4.泰坦尼克号乘客生存分类\n",
    "\n",
    "泰坦尼克号数据集\n",
    "- 数据地址：http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt\n",
    "- 数据集中是票的类别，存活，乘坐班pclass，年龄，登陆，home.dest，房间，票，船，性别\n",
    "- 乘坐班是指乘客班(1,2,3)，是社会经济阶层的代表\n",
    "- 其中年龄数据存在缺失\n",
    "\n",
    "泰坦尼克号生存分类模型\n",
    "- ①pd读取数据\n",
    "- ②选择有影响的特征，处理缺失值\n",
    "- ③进行特征工程，pd转换字典，特征抽取X_train.to_dict(orient='records')\n",
    "- ④决策树估计器流程\n",
    "- ⑤决策树的结构、本地保存\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba462c8-7fe1-45a1-87c7-d1cbdf9ee056",
   "metadata": {},
   "source": [
    "#### ①pd读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b360848a-d25c-4b8f-8afe-f7883030544b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   row.names pclass  survived  \\\n",
      "0          1    1st         1   \n",
      "1          2    1st         0   \n",
      "2          3    1st         0   \n",
      "3          4    1st         0   \n",
      "4          5    1st         1   \n",
      "\n",
      "                                              name      age     embarked  \\\n",
      "0                     Allen, Miss Elisabeth Walton  29.0000  Southampton   \n",
      "1                      Allison, Miss Helen Loraine   2.0000  Southampton   \n",
      "2              Allison, Mr Hudson Joshua Creighton  30.0000  Southampton   \n",
      "3  Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)  25.0000  Southampton   \n",
      "4                    Allison, Master Hudson Trevor   0.9167  Southampton   \n",
      "\n",
      "                         home.dest room      ticket   boat     sex  \n",
      "0                     St Louis, MO  B-5  24160 L221      2  female  \n",
      "1  Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female  \n",
      "2  Montreal, PQ / Chesterville, ON  C26         NaN  (135)    male  \n",
      "3  Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female  \n",
      "4  Montreal, PQ / Chesterville, ON  C22         NaN     11    male  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#读取泰坦尼克号数据集\n",
    "titanic = pd.read_csv(r\"E:\\jupyterlab\\ML\\titanic.csv\")\n",
    "\n",
    "print(titanic.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8557578-4218-416c-bf52-3cac7407bd2c",
   "metadata": {},
   "source": [
    "#### ②选择有影响的特征，处理缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96ece346-aebb-467f-ae04-ec6b18595876",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pclass      age     sex\n",
      "0    1st  29.0000  female\n",
      "1    1st   2.0000  female\n",
      "2    1st  30.0000    male\n",
      "3    1st  25.0000  female\n",
      "4    1st   0.9167    male\n",
      "   survived\n",
      "0         1\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         1\n"
     ]
    }
   ],
   "source": [
    "#处理数据，找出特征值和目标值\n",
    "\n",
    "#选择特征'pclass'、'age'、'sex'，其中特征'age'对应的特征值有缺失\n",
    "X = titanic.loc[:,['pclass','age','sex']]\n",
    "\n",
    "#目标值：\n",
    "Y = titanic.loc[:,['survived']]\n",
    "\n",
    "print(X.head())\n",
    "print(Y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8a6e9b7-0ba5-44f5-8964-d6ca156e01c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1313 entries, 0 to 1312\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   pclass  1313 non-null   object \n",
      " 1   age     633 non-null    float64\n",
      " 2   sex     1313 non-null   object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 30.9+ KB\n",
      "age中特征值的缺失率为： 0.5178979436405179\n"
     ]
    }
   ],
   "source": [
    "#查看数据可以发现'age'一列有缺失值\n",
    "X.info()\n",
    "\n",
    "#查看'age'中特征值的缺失率\n",
    "print('age中特征值的缺失率为：',X['age'].isnull().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26acb38b-7111-40f7-8d57-6b7f34b52d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#age中特征值的缺失率为： 51%，未达到70%，则保留特征，并对缺失值用平均值填补\n",
    "X['age'].fillna(X['age'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f962e9e3-e74c-420c-bcee-8f268169f933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#划分数据集为训练集和测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.25,random_state=2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6ac72b-8ddc-45dd-9a55-ec6ad61d112d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ③进行特征工程\n",
    "-pd转换字典，特征抽取X_train.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cee2157-ef38-4391-84e0-6cba60a0032a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#导入字典数据特征工程的类\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "#实例化字典数据特征工程的类\n",
    "dict = DictVectorizer(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e52b3f21-c389-460d-bfb3-ea7336da377d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#将训练集和测试集的特征值转换为字典\n",
    "X_train = X_train.to_dict(orient='records')\n",
    "X_test = X_test.to_dict(orient='records')\n",
    "\n",
    "#再对字典数据进行特征工程之特征抽取\n",
    "X_train = dict.fit_transform(X_train)\n",
    "X_test = dict.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c80ceb-2c07-4575-bce2-abebb40717a0",
   "metadata": {},
   "source": [
    "#### ④决策树估计器流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b31c8469-6487-4430-ae3d-e74158e4d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入决策树的类\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#实例化决策树的类\n",
    "treedec = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36c25435-e506-45a1-b226-43dfaa05eaf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测的准确率为： 0.7993920972644377\n"
     ]
    }
   ],
   "source": [
    "#带入训练集的数据得到决策树算法的模型\n",
    "treedec.fit(X_train,Y_train)\n",
    "\n",
    "#评估模型\n",
    "print('预测的准确率为：',treedec.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67e12c53-9bec-42a9-b806-8347bfde0c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'pclass=1st', 'pclass=2nd', 'pclass=3rd', 'sex=female', 'sex=male']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eec361-f8e4-445f-b897-aac9980abd66",
   "metadata": {},
   "source": [
    "#### ⑤决策树的结构、本地保存\n",
    "- sklearn.tree.export_graphviz()该函数能够导出DOT格式\n",
    "- sklearn.tree.export_graphviz(treedec,out_file=r\"E:\\jupyterlab\\ML\\tree.dot\",feature_names=dict.get_feature_names())\n",
    "- 工具：安装graphviz，将dot文件转换为pdf、png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a34555b6-62e9-410e-99ed-1755352ddb45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#导入导出决策树类中的方法\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "#导出决策树的结构\n",
    "export_graphviz(treedec,out_file=r\"E:\\jupyterlab\\ML\\tree.dot\",feature_names=dict.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6022793-b33b-4e37-8d78-22e9632142e8",
   "metadata": {},
   "source": [
    "### 5.决策树的优缺点\n",
    "\n",
    "优点：\n",
    "- 简单的理解和解释，树可视\n",
    "- 需要很少的数据准备，其他算法通常需要数据归一化\n",
    "\n",
    "缺点：\n",
    "- 由训练集很容易生成过于复杂的树，在测试集中表现不好，这种现象称为**过拟合**\n",
    "\n",
    "改进：\n",
    "- **减枝cart算法**(决策树API当中已经实现，随机森林参数调优有相关介绍)\n",
    "- **随机森林**\n",
    "\n",
    "注：\n",
    "- 企业重要决策，由于决策树很好的分析能力，在决策过程应用较多"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb72370-e636-4518-8669-765e989179a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <mark style=background-color:pink>二、集成学习方法-随机森林<mark>\n",
    "    \n",
    "**集成学习方法**：\n",
    "- 集成学习通过建立几个模型组合来解决单一预测问题。它的工作原理是**生成多个分类器/模型，各自独立的学习和作出预测，这些预测最后结合成单预测**，因此优于任何一个单分类器做出的预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2b5281-f281-48fd-8984-35549da1173e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.什么是随机森林\n",
    "\n",
    "**定义**：\n",
    "- 在机器学习中，随机森林是一个包含多个决策树的分类器，并且其输出的类别是由个别树输出的类别的众数而定\n",
    "- 例如，训练了五个树，其中4个树的结果是True，1个数的结果是False，那么最终结果会是True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd3c246-f83e-47bd-9bcc-8e5c9729cb11",
   "metadata": {},
   "source": [
    "### 2.随机森林的过程、优势\n",
    "\n",
    "数据集：N个样本，M个特征\n",
    "\n",
    "**随机森林建立多个决策树的过程**：\n",
    "- 1.随机在N个样本当中选择一个样本，重复N次，因为相当于**有放回地随机抽样N次**，所以最后抽到的N个数据中，可能会有重复的数据\n",
    "- 2.随机在M个特征当中选出m(<M)个特征\n",
    "- 3.重复多次，建立多个决策树，每个决策树的构成数据都是N个样本m个特征，数据之间各有不同\n",
    "\n",
    "**为什么要随机抽样训练集？**：\n",
    "- 如果不进行随机抽样，每棵树的训练集都一样，那么最终训练出的树分类结果也是完全一样的\n",
    "\n",
    "**为什么要有放回地抽样？**：\n",
    "- 如果不是有放回的地抽样，那么每棵树的训练样本都是不同的，都是没有交集的，这样每棵树都是'有偏的'，都是'片面的'，也就是说每棵树训练出来都是有很大的差异的：二随机森林最后分类取决于多棵树(弱分类器)的投票表决"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ad6d51-d3bc-477a-a81d-70ce487280d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.sklearn中的随机森林\n",
    "- 类：**sklearn.ensemble.RandomForestClassifier**\n",
    "- 实例化语法：**sklearn.ensemble.RandomForestClassifier(n_estimators=,criterion='gini',max_depth=None,bootstrap=True,random_state=)**\n",
    "- n_estimators：integer,optional(default=10) 森林里的数目数量{120,200,300,500,800,1200}\n",
    "- criterion：string，可选，树的分类依据默认基尼系数\n",
    "- **max_depth**：integer or None，默认为无，树的深度{5,8,15,25,30}\n",
    "- **max_features**：每个决策树的最大特征量{'auto','sqrt','log2','None'}\n",
    "- bootstrap：boolean,optional(default=True) 是否在构建树时有放回地抽样\n",
    "- 随机森林的超参数：森林中树的数量，每棵树的深度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfc29a4-277d-4766-8108-d4e767a5e2ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.随机森林：泰坦尼克号乘客生存分类分析及调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50997e6d-1198-4bfc-8343-0a8fe01b0f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入随机森林的类\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#实例化随机森林的类\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "#需要调优的参数\n",
    "param = {'n_estimators':[120,200,300,500,800,1200],'max_depth':[5,8,15,25,30]}\n",
    "\n",
    "#网格搜索与交叉验证(超参数调优)\n",
    "gc = GridSearchCV(rf,param_grid=param,cv=2)\n",
    "\n",
    "#传入数据\n",
    "gc.fit(X_train,Y_train)\n",
    "\n",
    "#查看最优参数\n",
    "print('最优参数为：',gc.best_params_)\n",
    "\n",
    "#查看最后模型\n",
    "print('最好的模型为：',gc.best_estimator_)\n",
    "\n",
    "#查看准确率\n",
    "print('准确率为：',gc.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5918fab5-4b06-424b-81f9-57c8978eb6ce",
   "metadata": {},
   "source": [
    "### 5.随机森林的优点\n",
    "- 在当前所有算法中，具有极好的准确率\n",
    "- 能够有效地运行在大数据集上\n",
    "- 能够处理具有高位特征的输入样本，而且不需要降维\n",
    "- 能够评估每个特征在分类问题上的重要性"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
