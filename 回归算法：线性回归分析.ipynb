{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d262f56-a55e-4f15-9f73-03cbdef29ccd",
   "metadata": {},
   "source": [
    "# 回归算法：线性回归分析\n",
    "\n",
    "- 分类型算法：目标值离散\n",
    "- 回归型算法：目标值连续\n",
    "- 回归型算法作用：房价预测，销售额预测，贷款额度..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9583dd4a-fe60-49fc-a0e9-1cc5d0e957e5",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## <mark style=background-color:pink>一、线性回归分析<mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b54cd-24d9-4f1f-82f5-ff3d940e0fc4",
   "metadata": {},
   "source": [
    "### 例：房子面积和价格的关系\n",
    "\n",
    "|编号|平方米|价格|\n",
    "|----|-----|----|\n",
    "|1|60|126|\n",
    "|2|72|151.2|\n",
    "|3|75|157.5|\n",
    "|4|80|168|\n",
    "|5|83|174.3|\n",
    "|6|87|180|\n",
    "|7|90|192.2|\n",
    "|8|93|194|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05200587-b2c0-48d0-ad82-4006322a6170",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAFsCAYAAAA30fmmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAxOAAAMTgF/d4wjAAAnlElEQVR4nO3de3xcdZ3/8dc705SStmjSFhHTJgsqFy/rpRQRERDl4iLqroK6UviVrogXXKuii7KyKqxX+D0UZC9YtYKirIvIgrqAVBG1pci6oLLKpSkpsNg2Cm0KDZPP/vE9odOYy6TNzCTfvJ+Px3l05lw/M5m+55zv+c45igjMzCwvTY0uwMzMxp/D3cwsQw53M7MMOdzNzDLkcDczy5DD3cwsQw53q5qkd0t64U4sp1rUs6vrl9Q6hnl3q9yOpI9Imj3KMs+TNHfQOuaOtEzFvNOrra2Y/xljmX+E9cyWtMdOLFfV66qYX5JOlPTmsW7LquNwt7H4CfDWkWaQ1CTpmZJeKGmxpI8Cv5a0XFJVnzdJCyS9QdIFko4ZZd4TgVslPaXqV5GWOxboknRclYucCFxSLLsHcDbQPMoy+wMXVjx/BvDTarcnaZWktirnf6WkS4vQnCPpIElvl/Rvkq6UtNfgBYovmx9L2rNi9KHAL0bakKQZkl5e8bwE3CPpz0dZbjdJL5P0ceDLwEuAaVW+Phsjv7E2KkmvAu4ApgMPSvoxcH1EfHyYRU4CAvg6cAVwAnDXKNt4JfAW4GBgLfBt4Erg9mHmbwZOBo4DXhIRTwyaPm3wuGJ8G/D+4rV0RsSmkeqq8Drgs8XjNwGfAN4m6VMx/C8B7wF+VfH8NcDFkt4L3BcR3xluYxFxmaSnAQcCP5Gk4bYj6fXA9cB/A7uR3pOHgG8BXwLuA4Y6ujmgmO/3FeOOBD41XF1FbY8VRy5fLF7D64EvR8Qvh1tG0oHAy4AHivlfFxF3j7Qd20UR4cHDiANwI3A68CJSKH4HeGkVy80F3ksK32q3dS1w2Bjm/3dSSO0DvB04FXgHsAZYOcwy7cC3xrCNFwIrisczgO+TdoyeR9qbbx5muf2A04vHs4F/IQX8T4ClVWx3r+L1fAfYDJw4zHzvBt5ZbGMW8GzgTGDhwHs6zHL/ADwVmFY8nwf8J+mI/lnA/iPU9vTifZxO+tJrquL1zCB9cbyw2Ma3gUMa/fnOdfCeu1VjLvAIcBhwDPBfxTCafyDtqd1ZHLI/mxQ+V0XEHwbPLOklwApgXXG0sD/wHNKe52cior+Yr4UUEAPzvAL4KqnJ6LCICEm7McSRaTH+QOBASV8AroiIW4pps4GjgJ9HxEMVi30GOL94/GHg3Ih4QtKDwJ3AjySdHhF3VGxnTlHfSZK6gN2BLmAj0BURlw5R277AG4F9SUc+64r17wd8FPjukO8ybADWF9t7F+lo6QXFsAR4fNB2did9GewLXAwcWzRPLQZ+DrwP6Ac+JelZEXHfoOUPJX3RdwAvJh0t/FDS2yNiyCM0Sc8Frga+BywiNWvdUGzPasDhbiOS1EFqkrmedGj/zYh4RdHuegQwMyKuldRJ+s++NzCftBc4E/gAsIAUPo8CfaTAHgjUk0h7s/9JCucbi01/jBQce5KaN+4AriumHUL6orgXuCciLi7W9duixij+vbbidbyRtBd8H2lv866IeLekN0m6nNQWPgt4JfAlSR0RsbloQrkaOLk4yXkf8AZJq4DLSE08W4H3S/pKRNxUnCQ8nBTK/xIR3y9qWAX8ju1fFIPdC6wGvhYR64t28q8Dp0XESG31zaQv3/WkL91fkJpbnllM362yWScithbnKg4vHt8OPBf4YkT8uqi1BLxncLAX7iSF/wxgVUR8aITaBjxM+js3AW8mfYHsAzwF+EMVy9sYOdxtNG8EriLtIb8ICEmfBkqkMHmw2OOdRwrdX5CaQx4EkLQuIk4fYf0/ApZFxFslTSu2cR/wcBGuTwX+SAp/ACLiRkkrSYf1zZIuIIXsj4F3FcEUQG/FMlcCVxYBfQ0wW9LBpD3H4yu+IJ4C3FBsex/gZ6TQfRapnfz7km4ujg7uBsoRsRxYXrGtb0i6itTefoKk/yKdc7iQdMLy7ZJ+DnwOuCYiHiuWC+CHRR2dxfxLI+Lekf5AwB7AY6Tg3IsUur1s///9BKnJ5pGKZX4L/LmkLcAjEbFc0qmSXhwRXyvWcc/gDUlP9hj6A+kE8R6SPkA6CvizYlunRsTvBy26F/Ae0ufke8BfkIL9c5IWDnzx2PhxuNuwirA9HPgl6T/ltcD/I4XOnIi4s2L2W4thsMeGO7kJEBEPSdpWPH0AKJOC8LfFuL2BXw6x/PuBi4DjSe3eQdrrf5wUPAdGxNohNnlOUf8ppKaJf6Xo9VJ8kTyb1JRBEar3Sno6sCUi/qdYx0BwbSEdiQzl/cDlpCaTY0nNJR+PiDslnQ8cTWoe2k3SFZWvr2ieOgk4OSI2D7P+Sk8nHT08hbRHvTepJ8r9xfQ+0hdAZbj3FvP9iNSsAvBN0hff10hNcQ9XbqQ46f03xeu/m9RMdyfpvMdm0hfMYxGxQzNQ4TWko5ZvkE5Ifywi1kn6voO9NhzuNpLTSb0grgeQ9AnSXtfbSG3JF0XEF0dZx1ZS88wfR5kHYBspqO5ke7A8l7Qn/yRJRwH/GxE3SHpLRPyuGH8uqT37Y5JeJ2kZac93WzF9oBfJD4AlEfHmYvx7Jf0jKQRXkU4yVgZhSzGNIui7ivEDzT87kLSQtBe9itTW/iCpueew4mjhUOCvgOdGxP3FMvuTvkgPBf4nIt47wvs12ItIgfsHUrv894AeUuBS1DJz0DLbSCedO4GnwZPNNa8qpj+b9GX7pIi4gdROjqSZpO6hXwZeGRH/PEqNXwH+WBwR/QXQKmlG8W8pIspjeL1WBYe7Daloa9+/ornijaQeEWcXz19O2jMdzVzS3vhIHpd0NKkbpEh7hHMlnUU6wTnQDj/QBbKnaJp5RjE/kk4Gvl80v0A6mXslaS/8nyTtDWyLiIuLk539Fdv/u4q98qHsTQpDSD1xLi4e786gcC+aqPYrvmDOJH3Z3CLp16Tmnt9JehTQQLAXphU1XQgcIukS4H9J5xluGyX85kbEQBPUt4p/r6+Y/nTSF1GlDaQuqhvZ/iUA8Fyl3yMsHrSOwT4FfDoiVko6QdLiiFgx1IxKPxb7BunEN6QvoRLpS/KzpL/RySNsy3aCw93+hNKPdF4LvK9oY11KOnT/SPEf9SBgdUQMuTde7JH9JalNdnMVTQtXALeRwu/J0C3q+CipiyMAEdHH9h/ZtLK9zf+HEbG+Yr4oAn+/4vkDbN8TXUDFnvkowQ6pPblH0jNJ3QoH+mc/g0HNMhHxKNu/9PYinSCFdAL5rKKHzQLS3nXlcneSjlig6Nuv1Df8bcB3JW0Auovp3cAHI2Jj8fwfhiq6COnlpCaa/x00+cKBv5+kn1WMv4vUX34aFe97xTpnkHoM/Sa299M/B7hD0nNIPYm2DlrsEODSoodRJ+l92z0iHpf0l6SjGBtvY+k36WFqDKS9yoHH84BZFc/fS2o7nTfKOl5Aaip48y7Wss9IdQLtO7HO6cDRY5h/HtAxxPgPAjNGWO4VA+8Tqc17xPdshPXMIh0x/CPpB0qlMSy7O/D5MW5v0VC1kpqrTgLmD7PMvaQvkbMqP0OD5juKdF5k7135XHgYfVDxhptVpWgW2SO27zWONO/sSHuyZk+SdEBE/KbRdeTO4W5mliFfOMzMLEMOdzOzDDnczcwy5HA3M8vQlOnnvttuu8W8efMaXYaZ2bhZv379tojYbahpUybc582bR3d39+gzmplNEpIGX6DtSW6WMTPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczswxNmX7uZmYTTUSwpquHtRu20Dl3Jgs7Wtl+D/Jd43A3M2uA7p5eFi9fzf2bemkuNdFX7md+WwsrliyivbVll9df82YZSc2SrpN0RPF8saSbJf1M0keGmP8KSaeOss7zJP2iWK+vKWBmk0pEsHj5aro29tJXDnq3lekrB10bezll+WrG4z4bNQ13SdOBa0j3jKS4f+IHSLfaOhQ4VtJhFfOfSLpp70jrPA54KbCQdHPd82pRu5lZrazp6qF701bK/TuGeLk/WLeplzVdPbu8jXqcUF0KrCke7w/cGRHbIt0I+X7SfRmRtBcp+C8ZZX3HAJcXy99Euvnun5C0TFL3wLB582j3aDYzq4+1G7YwrTR023pzqYm1G7bs8jZqGu5FiFderesW4ABJryuaXg4Bri+m/RPp5suj3XNzNrCuWH8AM4fZ9gUR0T4wzJo1axdeiZnZ+OmcO5O+cv+Q0/rK/XTOHTLWxqSuXSGLmyW/DCiT7hz/8Yh4TNJpwG8i4idVrOYRdgz0Pca/UjOz2lnY0cr8thZKTTvuvZeaxIK2FhZ2tO7yNurezz0iNgM9wAZgeTH69cBhklYCpwIfkvT6YVbxU1KbPZL2A4a95KWZ2UQkiRVLFtExp4XmkmiZXqK5JDrntLDitIPHpTtk3btCSpoGXACcUjSrEBHHV0w/F1gbEVdJOgO4KyJuqljFNcAHJV0EHAZcWLfizWxKqGX/8wHtrS3cuOzwydvPXVIzsGfFqLcAjwPLJV0bEZ+QNAv4OjADaAXeARARQ51cnQY8RGreaQZur2H5ZjbF1Lr/eSVJHNTZxkGdbeO6Xpg4XSFPBr4REUcDZwOfGGG1J5N6y7wAeM8o85qZVa0e/c/rpR7NMkvZHsBPdoUEkHQ/8NRBe+h7AQ8Mt7KxzGtmNhbV9D+vxV52LUykrpAUvzb9MFXsjY82r/u5m9lY1aP/eb1MiK6Q8GQTzjeBcyLinpHWU8287uduZmNVj/7n9TIhukJKKgFXANdGxJUjLT+Wec3MxqIe/c/rpe7hXtEV8m2x/ezEacCrgddIWinpymLeMyQdOWgVQ85rZrar6tH/vF40mc7+7or29vbo7u4efUYzm/Lq0c99PEhaHxHtQ03z9dzNzAapZf/zevFt9szMMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxDDnczsww53M3MMuRwNzPLkMPdzCxD0xpdgJlZtSKCNV09rN2whc65M1nY0YqkRpc1IdU83CU1A1cDn46IlZLeBJwJzAaujoiPFPOdBxwHPAScEhG/H2GdVc9rZnno7ull8fLV3L+pl+ZSE33lfua3tbBiySLaW1saXd6EU9NmGUnTgWuABRWjPwUcFRHPA46SdICk44CXAguBzwLnjbDOquc1szxEBIuXr6ZrYy995aB3W5m+ctC1sZdTlq8mIhpd4oRTjzb3pcCaiuebgP0ltQN7AA8AxwCXR0Q/cBNwyAjrG8u8ZpaBNV09dG/aSrl/xxAv9wfrNvWypqunQZVNXDUN94jYFhHdg0ZfBpwCvAu4DniE1ESzrlgmgJkjrLaqeSUtk9Q9MGzevHmXXouZNc7aDVuYVhq6bb251MTaDVvqXNHEV9feMpL2BQ6NiL+NiA8BZeAvSQFfGdJ7jLCaquaNiAsion1gmDVr1i5Wb2aN0jl3Jn3l/iGn9ZX76Zw70v7g1FTvrpAtpCaZFkm7AwcDAfwUOApA0n7ASCdIxzKvmWVgYUcr89taKDXtuPdeahIL2lpY2NHaoMomrrqGe0TcAfwHsJbU0+UB0gnXa4CXSLoI+BZwIYCkMyQdOWg1Q85rZvmSxIoli+iY00JzSbRML9FcEp1zWlhx2sHuDjkETZSzzJJmkLo3ro+I1eM174D29vbo7h7c/G9mk4n7ue9I0vqIaB9y2kQJ91pzuJtZbkYKd19+wMwsQw53M7MMOdzNzDLkcDczy5DD3cwsQw53M7MMOdzNzDLkcDczy5DD3cwsQw53M7MMOdzNzDLkcDczy5DD3cwsQ9MaXcDOkDSTdO/UhyLizkbXY5Y7X2p38ql5uEtqBq4GPg3cDNxYMXlP4OaIOL1i/iuA70fEV4ZZ3+7ADcD3gJdL+m5EfL5G5ZtNed09vSxevpr7N/XSXGqir9zP/LYWVixZRHtrS6PLs2HUtFlG0nTSnZMWAEREOSKOGBiAe4DPV8x/InDCKKt9PnB+RHwMeC/wmlrUbmZpj33x8tV0beylrxz0bivTVw66NvZyyvLVTJX7QUxG9WhzXwqsGTxS0tFAd0T8qni+F/AB4JKRVhYRqyLimuL+qR8Gvjb+JZsZwJquHro3baXcv2OIl/uDdZt6WdPV06DKbDQ1DfeI2BYRw93+6EPAJyue/xNpT/zRKld/DHAA8PBQEyUtk9Q9MGzevLnass2ssHbDFqaVhm5bby41sXbDljpXZNVqSG8ZSS8AHo2IruL5acBvIuIn1a6jaGd/I/CpYaZfEBHtA8OsWbPGoXKzqaVz7kz6yv1DTusr99M5d2adK7JqNaq3zKnA1yuevx54qqSVQCfwmKQ/RsRVgxeU9E5gr4g4B2gDfFxoViMLO1qZ39ZC18beHZpmSk1iQVsLCztaG1idjaRR/dyPJ/V4ASAijo+IlxUnWb8CfDIirpJ0hqQjBy37ZeA5km4BzgfeWaeazaYcSaxYsoiOOS00l0TL9BLNJdE5p4UVpx3s7pATmKbK2e729vbo7h6u+d/MRuJ+7hOTpPUR0T7UtEn5IyYzqy9JHNTZxkGdbY0uxarkyw+YmWXI4W5mliGHu5lZhhzuZmYZcribmWXI4W5mliGHu5lZhhzuZmYZcribmWXI4W5mliGHu5lZhhzuZmYZcribmWXI4W5mliGHu5lZhnw9d7NJzjfSsKE43M0mse6eXhYvX839m3ppLjXRV+5nflsLK5Ysor21pdHlWQPVvFlGUrOk6yQdUTFud0lrJD27eD5b0tWSbpG0StIBo6zzPEm/KNY7r7avwGxiiggWL19N18Ze+spB77YyfeWga2MvpyxfzVS5haYNrabhLmk6cA2wYNCkzwFfi4jfFs9PAW6LiEOBjwLnjrDO44CXAguBzwLnjXPZZpPCmq4eujdtpdy/Y4iX+4N1m3pZ09XToMpsIqjHCdWlwJqBJ0U4nwjMkHRkMfohYD9JM4GDgF+PsL5jgMsjoh+4CThkqJkkLZPUPTBs3rx5HF6K2cSxdsMWppWGbltvLjWxdsOWOldkE0lNwz0itkVE96DRFwHLgK8Cb5O0GLgZaAHeDbwQ+PYIq50NrCvWH8DMYbZ9QUS0DwyzZs3atRdjNsF0zp1JX7l/yGl95X465w75X8OmiLqeUJU0B2iOiBXF868BbwVeCZwbEb+U1AL8HHj+MKt5hB0DfY8almw2YS3saGV+WwtdG3t3aJopNYkFbS0s7GhtYHXWaHXt5x4RG4FtFSdBDwXuIYX1i4pxh4+ymp8CRwFI2g/4fQ1KNZvwJLFiySI65rTQXBIt00s0l0TnnBZWnHawu0NOcY3oCvlO4N8lNQObgTcCHcClkr4APAicASDpDOCuiLipYvlrgA9Kugg4DLiwnsWbTSTtrS3cuOxw93O3P6HJ2F1K0gzgOGB9RKyuZpn29vbo7h7c/G9mNnlJWh8R7UNNm5Q/YoqIx4CrGl2HmdlE5WvLmJllyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llqOpwl3RsLQsxM7PxU1W4S3od8OLalmJmZuNl1HuoSuoA3gm8tfblmJnZeBg23CVNA54BvA44EbhC0r3AVmA3YA7wbxHxb3Wo08zMxmCkPffLgKcDJ0dEj6Q3AFsior8+pZmZ2c4aNtwj4k2Sng6cIelh0t76vpK2AuuAiyKiXKc6zcxsDEZrc38sIv5e0oHAKyPiHQCS5pOaa75d4/rMzGwnDNtbRtLBwH9I+hvgd8A6SYdK2o/0pXBTnWo0M7MxGjbcI2JVRBwKPAj8EHgRqQ3+IOC1wEclLahLlWZmNiajdoWMiP+Q9D3gTOBHEfH72pdlZma7oqofMRUnTr8APFHbcszMbDyM5doypwF71KoQMzMbP6OGu6SZxcOHgL0lvVXS2ZJ2r21pZma2s0YMd0lHAz+VdALwc+BZwIHA7cBFkk6vfYlmZjZWI11+4CXAdOA84M+A5wOvAv4QEWdLuhH4fF2qNDOzMRlpz/0E4AZAwAbgm8A1wL9K+v9AU0S8veYVmjVARHDr2k1cueZ+bl27iYhodElmYzLS5QfOBpC0L3A/8DBQLrpG3gG8C/jsaBuQ1AxcDXw6IlYWTTlnAgNdKpcChwMnVyy2CNg3Ih4cZp13A93F059ExEdGq8OsWt09vSxevpr7N/XSXGqir9zP/LYWVixZRHtrS6PLM6vKqP3cgceB5wBHAE9IekpEdEm6SdK8kfq9S5oOfBdorxh9GHBSRNxZMe5u4EvFMocA7xoh2J8J/FdEvKGK2s3GJCJYvHw1XRt7KfcHfeV0+aSujb2csnw1Nyw7HEkNrtJsdNX8iOlzA4+LYD1H0i8j4mtVbmMp8ImK5y8DviDpqcDNwHtix2Pef2THvfjBXg68SNItpGalMyPi1iprMRvRmq4eujdtpdy/YzNMuT9Yt6mXNV09HNTZ1qDqzKo3pnuoRsTdEfF+4LeS3lzF/NsiYqD5ZOAa8csi4khS08uBpCOCgelHAb+NiPtHWO0vgaOLSyOczTBNQ5KWSeoeGDZv3lzFK7Spbu2GLUwrDb1n3lxqYu2GLXWuyGzn7NQNsiNiFXDjTiz3BHBd8bgPuAM4oGKWM4FLRlnNryLi7uLxLwYtX7mtCyKifWCYNWvWWMu1Kahz7kz6ykPfsqCv3E/n3JlDTjObaHYq3AEi4uGxLiNpf+AHkpolzQaOBW4rps0D9omI20dZzVckHVM8PglYM9Y6zIazsKOV+W0tlJp23HsvNYkFbS0s7GhtUGVmY7PT4b4zIuIuYCVwF3ALcHFxFABwHOnqk0+SdIakIwet5hzg/KLHzuuBM2patE0pklixZBEdc1poLomW6SWaS6JzTgsrTjvYJ1Nt0tBU6b/b3t4e3d3do89oRuo1s6arh7UbttA5dyYLO1od7DbhSFofEe1DTaumK6TZlCOJgzrb3DPGJq26NsuYmVl9ONzNzDLkcDczy5DD3cwsQw53M7MMOdzNzDLkcDczy5DD3cwsQw53M7MMOdzNzDLkcDczy5DD3cwsQw53M7MMOdzNzDLkcDczy5Cv526Tim+iYVadmoe7pGbgauDTEbFS0umkG2H/vphlaUTcPXi+EdY3C/g6MANoBd4REbfW8jXYxNDd08vi5au5f1MvzaUm+sr9zG9rYcWSRbS3tjS6PLMJpabNMpKmA9cACypGHwacFBFHFMPdw8w3nJOBb0TE0cDZwCfGu26beCKCxctX07Wxl75y0LutTF856NrYyynLVzNVbhdpVq16tLkvBdZUPH8Z8AVJt0v6vLYfUw+eb0gRcUlEfKN4uhfwwLhWaxPSmq4eujdtpdy/Y4iX+4N1m3pZ09XToMrMJqaahntEbIuIJ+9KLWkasCwijgQWAQcCRwyerxqS5gEfZpg9d0nLJHUPDJs3b975F2INt3bDFqaVhm5bby41sXbDljpXZDax1bW3TEQ8AVxXPO4D7gAOGOt6imacbwLnRMQ9w2zrgohoHxhmzZq1C5Vbo3XOnUlfuX/IaX3lfjrnzqxzRWYTW13DXdL+wA8kNUuaDRwL3DbGdZSAK4BrI+LKGpRpE9DCjlbmt7VQatpx773UJBa0tbCwo7VBlZlNTPXec78LWAncBdwCXBwRq4abX9IZko4cNPo04NXAayStlOSAnwIksWLJIjrmtNBcEi3TSzSXROecFlacdrC7Q5oNoqnSy6C9vT26u8fUrG8TkPu5m20naX1EtA81zT9isklFEgd1tnFQZ1ujSzGb0Hz5ATOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8uQw93MLEPTGl3ARBURrOnqYe2GLXTOncnCjlYkNbosM7OqONyH0N3Ty+Llq7l/Uy/NpSb6yv3Mb2thxZJFtLe2NLo8M7NR1bxZRlKzpOskHVE8f6OkVZJ+LOkSVewOSzpV0qVVrPM8Sb8o1jtvPOuNCBYvX03Xxl76ykHvtjJ95aBrYy+nLF9NRIzn5szMaqKm4S5pOnANsKB4PgN4K3BERLwceD7wkmLaPsD7gGWjrPM44KXAQuCzwHnjWfOarh66N22l3L9jiJf7g3WbelnT1TOemzMzq4l6nFBdCqwBiIjHIuK1EbFVUgmYAzwkqQm4DPgVsFhS2wjrOwa4PCL6gZuAQ4aaSdIySd0Dw+bNm6sqdu2GLUwrDd223lxqYu2GLVWtx8yskWoa7hGxLSK6h5l8FnBTRNwH/HVRy1mkgF9ZBP5QZgPrivUHMHOYbV8QEe0Dw6xZs6qquXPuTPrK/UNO6yv30zl3yM2ZmU0oDekKKenVwAlsb4JZBPxzRKyLiJuAx4BnDrP4I+wY6HuMZ20LO1qZ39ZCqWnHvfdSk1jQ1sLCjtbx3JyZWU3UPdwlHQacD7w2IrYWo38N7FdMnwfMB9YPs4qfAkcV8+4H/H6c62PFkkV0zGmhuSRappdoLonOOS2sOO1gd4c0s0mhEV0hv0na+/5WEZSfAb4MXCLpR8CewIciYoukM4C7ir35AdcAH5R0EXAYcOF4F9je2sKNyw53P3czm7Q0Gbv2Fb1ujgPWR8TqapZpb2+P7u7hmv/NzCYfSesjon2oaZPyR0wR8RhwVaPrMDObqHxtGTOzDDnczcwy5HA3M8uQw93MLEMOdzOzDDnczcwy5HA3M8vQpPwR086Q9Dg7d6mCWUB1l5S0eqrX32Uy/f3rUetEeT9y+/vv7HbmRcRuQ02YMuG+syR1D/cLMGucev1dJtPfvx61TpT3I7e/fy2242YZM7MMOdzNzDLkcB/dBY0uwIZUr7/LZPr716PWifJ+5Pb3H/ftuM3dzCxD3nM3M8uQw93MxkTScyS9SlJ1Nya2UdXiPXWzjE14kk4DTq4YtQg4HXgX8DjppurviF38MA+znU8BJ7L9NxJLI+LuXdnOZCFpNnAZMJd074dTgUOA1wG3A28AXhIRj9a5jiXAxRWz7AncHBGn17KO8SDpacBFpNdSBt4JHEot3tOI8DBoIH2ILy0ePxtYTbp36+mNrm2qD6Rw+TZwNbB7Me4W4JAabOdyUqg8t9Gve1Bts4vXfwuwCjigFp9T0pfn3xePjyXdIvNcYFox7tvAoXV4vX9Sx6Dp1wDPGYftPA24ErgJuIF0X+dxfV+BfwUWF4+PAW6s1Xva8A/qRBuAfYA7gD2K56uAVwAq/uALGl3jVB6AlcD8iucl4C7gz2qxHWBt8Z/9duDzFEe7DX4Phgrdcf+ckvYiLwdmAucAHy3GzwT+CvgZMKMOr3fIOoppRwOXjNN2hgrecX1fgZ8D+xWP9wNuq9V76jb3CpKaSHtqvwIWS2oDnhERP4z0F/gBcGQja5zKJB0F/DYi7q8YfRZwU0TcN97bAR4ElkXEkaQmmgOBI8ZrO7vgIWA/STOBg4BfU5vP6c1AC/Bu4IWkvUqAvYGTgIeBerTrDlcHwIeAT47Tdp5HCnNIX+qdjP/7ehnwUUkvJ3V/vKwYP+7vqcN9R39Nek/OIgX8bcC6iul/BJ7egLosORO4ZOCJpFcDJwDLarGdiHgCuA4gIvpIR3QHjPO2dsbgsPshtfmcfgY4NyI+CbwV+DpARPwuIk4EtgCvHoft7FQdkl4APBoRXeO0ncHB+xXG+X2NiItI53GOIjX5fLEYP+7vqcN9R4uAf46IdRFxE/AH0n+eAbNJh2dWZ5LmAftExO3F88OA84HXRsTWWmxH0v7ADyQ1Fyf1jiV94Tfa4LBbQTqsHzBen9OZwIuKx4cDknSnpD2Lca1AzzhsZ6x1DDiVIujHwxDB+3lq8L5GxC+BlwLvAJ6o1XvqcN/Rr0ntYAP/yfcCuiUNfFsvBO5tUG1T3XGkPdQB3wRmAN+StFLSX4z3diLiLlLb+12kk5cXR8Sq4Retm8Fh9yhADT6nHwfeKWkzKejeC3wY+J6kn5Dai1eOw3bGWsfAkdrxpHbwcVMZvBHxRxj/91XSicCDEXF9RJSp0XvqrpAVJM0gHfbvQ+pe9UmgD3gfqS3uSGBhRGxpWJE25RXNEZcC+5POC5xB+rz6c7qLiuA9PiIWF8/fwiR9Xx3uVZB0IOlky/ci4pFG12M2FH9Oa2Oyvq8OdzOzDLnN3cwsQw53s10kadgeFJIOqWctZgOmNboAs8lG0utJ/Z0XAE8FdpP0twO9K4p5ZpB+YLNN0n9PlpNwlg+Hu9nYrSL94G1zRHxomHnaSBeHeh+wh6QFpC+Ew0g/L/+7ulRqU5abZczG7kHSNW0ulXSopKWSzh34IUpx2YoXA88hhftepL7MtwHfARp+g2nLn8PdrEqSTpf0aeBtpD7mf076lexXST8sOquY9eWkXzfvGRHnR8QdwL1Fs8084Pp6125Tj8PdrHq3Av3AvwDNwO7AncV1ZwRcBRAR3wEOBu6Q9DFJ04rHbyJdFOraBtRuU4zD3ax6vwHmFlcI3AL0sv0mHvsW05F0UDH+NxHx98UFyJ5Jui74U9nxekVmNeFwN6tScYGypqJtfaDd/QBJxwP7RsQmSS3AUyLiq6QmGCS9gnT1wntJN9n4oCRfOtpqyuFuNjarSTfx+BKwMiJOIp0wvRUgInojYuBiViVJuwEPFFccpNiLP4m0129WM778gNkuKm6aoYjYPGj83IjY0KCybIpzuJuZZcjNMmZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpah/wOYAvpUFuShowAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#绘图看看面积和房价的关系\n",
    "\n",
    "#导入pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#数据\n",
    "X = [60,72,75,80,83,87,90,93]\n",
    "Y = [126,151.2,157.5,168,174.3,180,192.2,194]\n",
    "\n",
    "#设置字体，防止中文和负号乱码\n",
    "plt.rcParams['font.sans-serif'] = ['KaiTi']\n",
    "plt.rcParams['axes.unicode_minus']=False\n",
    "\n",
    "\n",
    "#散点图scatter\n",
    "plt.figure(figsize=(5,5),dpi=80)\n",
    "plt.title('房子面积和价格之间的关系')\n",
    "plt.xlabel('面积')\n",
    "plt.ylabel('房价')\n",
    "plt.xticks(X)\n",
    "plt.yticks(Y)\n",
    "plt.scatter(X,Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846226fc-bffd-437b-b53d-f3e88654ef21",
   "metadata": {},
   "source": [
    "从上图可以看出，面积和房价之间存在**线性关系**\n",
    "\n",
    "**线性关系**：\n",
    "- 二维：直线关系\n",
    "- 三维：平面\n",
    "- 四维：..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab374977-0ad7-462d-b4e1-ab6be4f5e8d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 线性关系模型\n",
    "- 一个通过属性(特征)的线性组合来进行预测的函数\n",
    "- **$f(x) = w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} + ... + w_{k}x_{k} + b$**\n",
    "- $f(x)$：目标值，预测值\n",
    "- $w_{i}$：每个属性(特征)的权重\n",
    "- b：偏置项，误差项，可以理解为：$w_{0}x_{0}$，$x_{0}=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da86a7-bbf4-4d78-b234-a7dc7e181202",
   "metadata": {},
   "source": [
    "### 线性回归\n",
    "- 定义：线性回归通过一个或者多个自变量与因变量之间进行建模的回归分析\n",
    "- 一元线性回归：自变量只有一个\n",
    "- 多元线性回归：自变量有两个或两个以上\n",
    "- 通用公式：$h(w) = w_{0}x_{0} + w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} +... = W^{T}X$，其中W、X为列向量，$x_{0} = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6464ece-e1e6-4ac4-812d-6e178ad79175",
   "metadata": {},
   "source": [
    "### 迭代的算法\n",
    "- 回归、神经网络...\n",
    "- 因为预测的时候预测值和真实值之间有差距，也就是**误差**\n",
    "- 算法通过不断迭代，使得**误差**达到最小值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69804d0-fdf9-4363-b34c-9d1471657e8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 损失函数\n",
    "- 误差的大小\n",
    "- $y_{i}$：第i个训练样本的真实值\n",
    "- $h_{w}(x_{i})$：第i个训练样本特征值组合预测函数\n",
    "- 总损失定义：$J(\\theta)=\\sum_{i=1}^{m} (h_{w}(x_{i}) - y_{i})^{2}$，又称为最小二乘法\n",
    "- 如何去求模型当中的$W$(各特征的权重系数)，使得损失函数取得最小值？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4de3db-cf2d-466d-bf82-3093e0cbbb00",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 损失函数达到最小值：最小二乘法之正规方程(不作要求)\n",
    "- 求解：$W = (X^{T}X)^{-1}X^{T}Y$\n",
    "- X：特征值矩阵\n",
    "- Y：目标值矩阵\n",
    "- 直接求到最小值\n",
    "- 缺点：当特征过于复杂时，求解速度太慢"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9ab737-198a-49f2-9346-a80fc6d32490",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 损失函数达到最小值：最小二乘法之梯度下降\n",
    "- 学习率：lr\n",
    "- 给定初始权重$W$：${w_{0},w_{1}...}$\n",
    "- 通过初始权重，学习率，和**损失函数在初始权重的梯度**，不断迭代，直到找到最优权重，使得损失函数达到最小值(可能是局部最小值)\n",
    "- $w_{i} = w_{i} - lr*gradJ(W)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9194c57-8cb1-49b6-86fc-b9f2c47d557e",
   "metadata": {},
   "source": [
    "### sklearn中的线性回归之正规方程、梯度下降\n",
    "正规方程：**sklearn.linear_model.LinearRegression**\n",
    "- 普通最小二乘线性回归\n",
    "- coef_：回归系数，也就是权重\n",
    "\n",
    "梯度下降：**sklearn.linear_model.SGDRegressor**\n",
    "- 通过使用SGD最小化线性模型\n",
    "- coef_：回归系数，也就会权重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c80448f-d049-4957-a4e0-706b5fe23ad0",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## <mark style=background-color:pink>二、线性回归实例<mark>\n",
    "- 波士顿房价数据集\n",
    "    \n",
    "|属性名|解释|类型|\n",
    "|------|---|----|\n",
    "|CRIM|该镇的人均犯罪率|连续型|\n",
    "|ZN|占地面积超过2.5万平方尺的住宅用地比例|连续型|\n",
    "|INDUS|非零售商业用地比例|连续型|\n",
    "|CHAS|是否邻近Charles River|离散型，1=邻近，0=不邻近|\n",
    "|NOX|一氧化氮浓度|连续型|\n",
    "|RM|每栋房屋的平均客房数|连续型|\n",
    "|AGE|1940年之间建成的自用单位比例|连续型|\n",
    "|DIS|到波士顿5个就业中心的加权距离|连续型|\n",
    "|RAD|到径向公路的可达性指数|连续型|\n",
    "|TAX|全值财产税率|连续型|\n",
    "|PTRATIO|学生与教师的比例|连续型|\n",
    "|B|1000(BK-0.63)^2,其中BK为黑人占比|连续型|\n",
    "|LSTAT|低收入人群占比|连续型|\n",
    "|MEDV|同类房屋价格的中位数|连续型|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56ebbfa-53e0-4fb3-8599-5a094e28db0d",
   "metadata": {},
   "source": [
    "### ①波士顿地区房价数据获取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e13c8292-0fc1-4b1f-897f-d9be04f0df5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#导入波士顿房价数据集的类\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "#实例化波士顿房价数据集的类\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed898a80-538f-47c4-9a7a-2510a262f258",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ②波士顿地区房价数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc544e63-eae5-49a7-9dae-3ae9cede6833",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'boston' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25944/618672935.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#将波士顿数据集划分为训练集的数据(特征值)，测试集的数据(特征值)，训练集的目标值，测试集的目标值\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboston\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mboston\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2021\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'boston' is not defined"
     ]
    }
   ],
   "source": [
    "#导入划分训练集和测试集的方法\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#将波士顿数据集划分为训练集的数据(特征值)，测试集的数据(特征值)，训练集的目标值，测试集的目标值\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(boston.data,boston.target,test_size=0.25,random_state=2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796fa4d7-41fb-43a7-8429-e4400c0c4d75",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ③训练集和测试集数据标准化处理\n",
    "- 训练集和测试集的每个特征对应的特征值需要标准化处理\n",
    "- 训练集和测试集的目标值也需要标准化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c93800cb-5f4f-4e27-9b38-c726adea87ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#导入特征工程中标准化处理的类\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#实例化两个征工程中标准化处理的类\n",
    "std_X = StandardScaler()\n",
    "std_Y = StandardScaler()\n",
    "\n",
    "#对训练集和测试集的每个特征对应的特征值进行标准化处理\n",
    "X_train = std_X.fit_transform(X_train)\n",
    "X_test = std_X.transform(X_test)\n",
    "\n",
    "#对训练集和测试集的目标值进行标准化处理,传入数据必须要求是二维的\n",
    "Y_train = std_Y.fit_transform(Y_train.reshape(-1,1))\n",
    "Y_test = std_Y.transform(Y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de981d7b-da22-4f72-8c1b-5ac1debc3632",
   "metadata": {},
   "source": [
    "### ④使用最简单的线性回归模型LinearRegression和梯度下降估计SGDRegressor对房价进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e66149f-9582-428b-b0ed-f243c8d7d90f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "线性回归模型中的回归系数为： [[-0.12423822  0.12444786  0.00773058  0.09499624 -0.21800985  0.28141578\n",
      "   0.0391382  -0.32841954  0.32495953 -0.22049101 -0.20512339  0.10095817\n",
      "  -0.44777257]]\n",
      "测试集里面每个房子的预测价格为： [22.85885078 16.0936965  21.88581704 12.81402904 37.387188   19.08792846\n",
      " 27.43157599 29.35355651 24.0672894  32.93671349 41.07338339 26.46858395\n",
      " 16.89146608 42.25600814 33.45093863 24.02040864 22.80646716  8.02368765\n",
      "  8.41846203 33.67776781 21.431452   13.57186613 13.03136441 31.77215959\n",
      " 12.89376459 18.33090313 19.95490044 25.6948347  23.39034633 16.76955753\n",
      " 19.47077071 31.06925511 13.47065759 24.73016956 29.85463255 16.65701344\n",
      " 26.61197027 17.41344934 34.27779067 26.51024382 20.47895716 28.32961965\n",
      " 32.09154687 31.37391954  8.69764661 28.52740006 21.16745058 26.30199138\n",
      " 23.97364206 29.53317702 16.85152895 41.40738495 20.59391001 31.71210733\n",
      " 18.94230561 22.01696073 24.14991303 23.59023812 34.45328216 22.88694969\n",
      " 36.31302303 20.339557   12.21413557 24.61540623 25.93316327 21.95277138\n",
      " 22.58058049 26.53173144 21.18557543  2.40507273 19.96508012 35.10627728\n",
      " 25.21990804 30.29918372 23.57088893  8.85338331 20.28648876 15.98540933\n",
      " 23.4543222  21.64696929 17.39777948 15.6793041   8.89083299 16.43418976\n",
      " 24.88664885 21.63432274 27.44426915 14.17539357 28.54988388 18.23026687\n",
      " 26.90351213 13.67285646 31.18056416 24.90011628 20.93245168 22.91462621\n",
      " 27.41413545 10.56667232 18.0583328  17.11615393 29.03219081 20.68770442\n",
      " 20.48442139 21.61360858 31.79182938 -6.89627364 13.19522647 32.74005433\n",
      " 33.41163201 34.20636535 19.08275429 24.56490877 31.82053494 24.72138572\n",
      " 19.03817513 25.77771291 27.69070056 16.09863977 17.8776938  13.42948594\n",
      "  8.15049755 28.12849694 20.131988    6.81355376 18.8208107  17.12884929\n",
      " 17.27274229]\n"
     ]
    }
   ],
   "source": [
    "#导入正规方程求解的类\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#实例化\n",
    "lr = LinearRegression()\n",
    "\n",
    "#用标准化处理过后的训练集数据和特征值带入线性回归算法中训练得到模型\n",
    "lr.fit(X_train,Y_train)\n",
    "\n",
    "#使用参数_coef看最后得到的线性回归模型中的权重\n",
    "print('线性回归模型中的回归系数为：',lr.coef_)\n",
    "\n",
    "#可以预测测试集的房子价格\n",
    "Y_test_predict_lr = lr.predict(X_test)\n",
    "print('测试集里面每个房子的预测价格为：',std_Y.inverse_transform(Y_test_predict_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b834acef-27d9-4284-9ed2-1c8127f6759a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "线性回归模型中的回归系数为： [-0.10287881  0.08686818 -0.04751992  0.09930885 -0.13964618  0.31838748\n",
      "  0.01882848 -0.27172511  0.17435356 -0.07563393 -0.18626783  0.10534178\n",
      " -0.4210168 ]\n",
      "测试集里面每个房子的预测价格为： [22.73133873 16.10628167 21.80025013 13.37308713 37.1833794  19.38659124\n",
      " 27.17629525 28.7858721  23.88388107 32.5517625  41.04729248 26.00611281\n",
      " 16.86495738 41.74629237 33.12885005 23.64483933 22.71883615  8.68483189\n",
      "  9.06892074 33.22633873 21.2921399  13.66037096 13.34901957 31.41564305\n",
      " 13.43628103 18.8105406  20.1442147  25.31705954 23.37796062 16.75642736\n",
      " 19.28486357 30.63516901 13.79654714 24.56580392 29.36925031 16.71620215\n",
      " 26.16220379 17.86269706 33.67387237 26.36309087 20.50234433 27.94886332\n",
      " 31.40751467 30.98275931  8.80280929 28.51484329 21.02366495 25.827185\n",
      " 23.83211496 29.19593909 16.83644697 40.88338708 20.30802281 31.37208649\n",
      " 18.70960781 22.07347996 23.9232422  23.3719246  34.15631527 22.74811772\n",
      " 35.83956568 20.25654174 12.76882647 24.64468498 25.78953453 21.96792085\n",
      " 22.58417746 26.25031845 21.01025056  2.93434171 20.35031388 34.74123736\n",
      " 24.95294989 30.09143615 23.46113441  9.56654485 20.30533932 16.49373835\n",
      " 23.76718704 22.05089818 17.89246443 15.26359244  9.53247122 16.70810489\n",
      " 24.34711777 21.75995065 27.3232769  14.69899265 28.45291289 18.69137509\n",
      " 26.60409239 13.81035452 30.74980833 24.44873505 20.73056538 22.77945256\n",
      " 26.9619627  10.49867094 18.02506176 17.59317279 29.18606325 20.37312065\n",
      " 20.41301304 21.6288287  31.10268508 -5.85642151 13.49460809 32.27863643\n",
      " 33.10814269 33.86669466 19.54611096 24.83814209 31.257774   24.58437496\n",
      " 18.80752101 25.65893461 27.2423175  16.53126694 18.28481609 13.95413916\n",
      "  8.30319285 27.73976833 19.9883979   7.51229262 18.29262289 17.23505126\n",
      " 17.71202594]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#导入梯度下降求解的类\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "#实例化\n",
    "sgd = SGDRegressor()\n",
    "\n",
    "#用标准化处理过后的训练集数据和特征值带入线性回归算法中训练得到模型\n",
    "sgd.fit(X_train,Y_train)\n",
    "\n",
    "#使用参数coef_看最后得到的线性回归模型中的权重\n",
    "print('线性回归模型中的回归系数为：',sgd.coef_)\n",
    "\n",
    "#可以预测测试集的房子价格\n",
    "Y_test_predict_sgd = sgd.predict(X_test)\n",
    "print('测试集里面每个房子的预测价格为：',std_Y.inverse_transform(Y_test_predict_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7ae941-907b-4932-89a6-ee59f9e99ac2",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## <mark style=background-color:pink>三、回归性能评估<mark>\n",
    "\n",
    "均方误差(Mean Squared Error,MSE)评价机制:\n",
    "- $MSE=\\frac{1}{m}\\sum^{m}_{i=1}(y^{i}-(y_{predict})^{i})^{2}$\n",
    "- 类：**sklearn.metrics.mean_squared_error** \n",
    "- 实例化语法：**sklearn.metrics.mean_squared_error(Y_test,Y_test_predict)**\n",
    "- Y_test：测试集的真实目标值，**标准化之前的值**\n",
    "- Y_test_predict：测试集的预测目标值，**标准化之前的值**\n",
    "- 返回：浮点数结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65d7af0c-6490-4178-b18b-332c9418b826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正规方程求解线性回归的均方误差： 22.641818640133717\n",
      "梯度下降求解线性回归的均方误差： 22.301586301128822\n"
     ]
    }
   ],
   "source": [
    "#导入均方误差的类\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print('正规方程求解线性回归的均方误差：',mean_squared_error(std_Y.inverse_transform(Y_test),std_Y.inverse_transform(Y_test_predict_lr)))\n",
    "print('梯度下降求解线性回归的均方误差：',mean_squared_error(std_Y.inverse_transform(Y_test),std_Y.inverse_transform(Y_test_predict_sgd)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac6e0c0-cb36-47d4-ac0a-49467feb7f22",
   "metadata": {},
   "source": [
    "### 对比：正规方程和梯度下降\n",
    "\n",
    "|梯度下降|正规方程|\n",
    "|-------|--------|\n",
    "|需要学习率|无需学习率|\n",
    "|当特征量n很大时也能较好地使用|涉及逆矩阵运算，当特征数量大时运算代价大，通常n小于10000时还是可以接受的|\n",
    "|适用于各种类型的模型|只适用于线性模型，不适合逻辑回归模型等其他模型|\n",
    "\n",
    "\n",
    "- 小规模数据：LinearRegression(不能解决**拟合**问题)以及其它\n",
    "- 大规模数据：SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d540b0-6fa1-4c5f-abeb-ccf156626391",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <mark style=background-color:pink>四、过拟合和欠拟合<mark>\n",
    "**线性回归**：\n",
    "- 线性回归\n",
    "- 非线性回归\n",
    "\n",
    "**问题**：\n",
    "- 训练数据训练的很好，误差也不大，但是在测试集上表现差\n",
    "\n",
    "**欠拟合**：\n",
    "- 欠拟合直观感觉：得到的特征太少，导致区分标准太粗糙，不能准确识别\n",
    "- 欠拟合概念：一个假设在训练数据上不能获得更好地拟合，但是在训练数据外的数据集上也不能很好地拟合数据，此时认为这个假设出现了欠拟合的现象(模型过于简单)\n",
    "- 欠拟合原因：学习到数据的特征过少\n",
    "- 解决办法：增加数据的特征数量\n",
    "\n",
    "**过拟合**：\n",
    "- 过拟合直观感觉：得到的特征过多过细，导致区分标特殊特有化，不能准确识别\n",
    "- 过拟合概念：一个假设在训练数据上能够获得比其它假设更好地拟合，但是在训练数据外的数据集上却不能很好地拟合数据，此时认为这个假设出现了欠拟合的现象(模型过于复杂)\n",
    "- 过拟合原因：原始特征过多，存在一些嘈杂特征，模型过于复杂是因为模型尝试去兼顾哥哥测试数据点\n",
    "- **解决办法**：①进行特征工程中的特征选择，消除关联性打的特征(很难做)②交叉验证(让所有数据都有过训练)**③正则化**\n",
    "\n",
    "**特征选择**：\n",
    "- 过滤式：低方差特征\n",
    "- 嵌入式：正则化、决策树、神经网络\n",
    "\n",
    "**正则化**：\n",
    "- 减少回归模型中高次项的权重，尽量减小高次项特征的影响 \n",
    "- 线性回归中 LinearRegression 容易出现过拟合现象 可以通过L2正则化解决这种现象\n",
    "\n",
    "**L2正则化**：\n",
    "- 作用：可以使得W的每个元素都很小，都接近于0\n",
    "- 优点：越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象\n",
    "- L2正则化：Ridge：岭回归，带有正则化的线性回归，解决线性回归的过拟合的方式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a37f42-829d-4640-be06-b7009cea4f73",
   "metadata": {},
   "source": [
    "## <mark style=background-color:pink>五、岭回归<mark>\n",
    "\n",
    "- 类：**sklearn.linear_model.Ridge**\n",
    "- 实例化语法：**sklearn.linear_model.Ridge(alpha=1.0)**\n",
    "- 具有L2正则化的线性最小二乘法\n",
    "- alpha：正则化力度，**超参数**，可以进行网格搜索，0\\~1或1\\~10\n",
    "- coef_：回归系数\n",
    "\n",
    "线性回归正规方程求解LinearRegression与线性回归岭回归求解对比：\n",
    "- 岭回归：**得到的回归系数更符合实际，更可靠**。能扔估计参数的波动为变小变得更稳定，在病态数据偏多的研究中有较大的实用价值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a5c69a6-5e13-442f-9796-17486f4c4255",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "线性回归模型中的回归系数为： [[-0.12297918  0.12240591  0.00406447  0.09541165 -0.21393325  0.28295785\n",
      "   0.03793679 -0.32490384  0.31498798 -0.211226   -0.20381663  0.1009112\n",
      "  -0.44548659]]\n",
      "测试集里面每个房子的预测价格为： [[23.11541332]\n",
      " [15.698114  ]\n",
      " [22.22176945]\n",
      " [13.21738462]\n",
      " [37.37885882]\n",
      " [19.71208664]\n",
      " [27.10191411]\n",
      " [29.0951965 ]\n",
      " [24.006866  ]\n",
      " [33.3235392 ]\n",
      " [39.99624399]\n",
      " [26.45353187]\n",
      " [17.21800424]\n",
      " [41.43845447]\n",
      " [33.26855262]\n",
      " [23.86141763]\n",
      " [22.82266673]\n",
      " [ 8.23524111]\n",
      " [ 8.70845078]\n",
      " [33.34963848]\n",
      " [21.54545211]\n",
      " [13.2566594 ]\n",
      " [13.01983312]\n",
      " [31.03004897]\n",
      " [14.39715787]\n",
      " [18.65482505]\n",
      " [22.02735394]\n",
      " [25.03536418]\n",
      " [23.05560137]\n",
      " [17.20557638]\n",
      " [19.54371802]\n",
      " [31.92162495]\n",
      " [13.40331339]\n",
      " [24.75995492]\n",
      " [28.7139125 ]\n",
      " [15.98748704]\n",
      " [26.90196227]\n",
      " [17.62948421]\n",
      " [32.99466381]\n",
      " [27.05374453]\n",
      " [20.24814838]\n",
      " [28.40107701]\n",
      " [30.64097725]\n",
      " [30.80584098]\n",
      " [ 8.73793788]\n",
      " [29.35648296]\n",
      " [21.16765701]\n",
      " [24.92353695]\n",
      " [24.17716485]\n",
      " [30.13464245]\n",
      " [17.36669694]\n",
      " [40.80297795]\n",
      " [20.21673628]\n",
      " [31.17832614]\n",
      " [18.47906479]\n",
      " [22.56689672]\n",
      " [23.6233895 ]\n",
      " [23.40338879]\n",
      " [34.59356389]\n",
      " [22.98006875]\n",
      " [35.14149862]\n",
      " [19.81772373]\n",
      " [12.70300666]\n",
      " [25.20483621]\n",
      " [25.76983401]\n",
      " [21.74686532]\n",
      " [22.58714435]\n",
      " [26.80936542]\n",
      " [21.71088036]\n",
      " [ 2.54245166]\n",
      " [20.03431199]\n",
      " [34.85611741]\n",
      " [25.08632051]\n",
      " [30.82891246]\n",
      " [23.9371028 ]\n",
      " [11.35968856]\n",
      " [19.99142606]\n",
      " [16.76968845]\n",
      " [23.57869546]\n",
      " [22.50699192]\n",
      " [17.64651955]\n",
      " [14.47520256]\n",
      " [ 9.78765111]\n",
      " [16.25928306]\n",
      " [23.49655603]\n",
      " [20.7557308 ]\n",
      " [26.76311361]\n",
      " [14.10676204]\n",
      " [28.28463001]\n",
      " [18.80208029]\n",
      " [27.06787546]\n",
      " [13.38470063]\n",
      " [30.21381199]\n",
      " [25.1512547 ]\n",
      " [20.55490786]\n",
      " [23.0788171 ]\n",
      " [27.06295132]\n",
      " [10.23456777]\n",
      " [17.95503169]\n",
      " [17.8687299 ]\n",
      " [29.68050506]\n",
      " [20.6685244 ]\n",
      " [19.83997697]\n",
      " [21.22007012]\n",
      " [31.13303951]\n",
      " [-6.20526796]\n",
      " [15.1635369 ]\n",
      " [32.61717853]\n",
      " [33.39811032]\n",
      " [34.51172594]\n",
      " [19.87035703]\n",
      " [24.29389783]\n",
      " [30.58691443]\n",
      " [25.1883659 ]\n",
      " [18.39836452]\n",
      " [25.88315689]\n",
      " [27.38530905]\n",
      " [17.12931917]\n",
      " [18.73674134]\n",
      " [13.97893805]\n",
      " [ 7.58304452]\n",
      " [27.49584729]\n",
      " [20.09184735]\n",
      " [ 7.46403449]\n",
      " [16.76018705]\n",
      " [17.02257704]\n",
      " [17.66006304]]\n"
     ]
    }
   ],
   "source": [
    "#导入梯度下降求解的类\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#实例化\n",
    "ri = Ridge(alpha=1.0)\n",
    "\n",
    "#用标准化处理过后的训练集数据和特征值带入线性回归算法中训练得到模型\n",
    "ri.fit(X_train,Y_train)\n",
    "\n",
    "#使用参数coef_看最后得到的线性回归模型中的权重\n",
    "print('线性回归模型中的回归系数为：',ri.coef_)\n",
    "\n",
    "#可以预测测试集的房子价格\n",
    "Y_test_predict_ri = ri.predict(X_test)\n",
    "print('测试集里面每个房子的预测价格为：',std_Y.inverse_transform(Y_test_predict_ri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7852ca43-3c1e-44f6-8b6f-2b5cae97f483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正规方程求解线性回归的均方误差： 22.641818640133717\n",
      "梯度下降求解线性回归的均方误差： 22.301586301128822\n",
      "岭回归求解线性回归的均方误差： 22.566779390046353\n"
     ]
    }
   ],
   "source": [
    "print('正规方程求解线性回归的均方误差：',mean_squared_error(std_Y.inverse_transform(Y_test),std_Y.inverse_transform(Y_test_predict_lr)))\n",
    "print('梯度下降求解线性回归的均方误差：',mean_squared_error(std_Y.inverse_transform(Y_test),std_Y.inverse_transform(Y_test_predict_sgd)))\n",
    "print('岭回归求解线性回归的均方误差：',mean_squared_error(std_Y.inverse_transform(Y_test),std_Y.inverse_transform(Y_test_predict_ri)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
